{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\prass\\\\OneDrive\\\\desktop\\\\practise\\\\new_env\\\\text-classification-using-BERT\\\\src'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows-SSD\n",
      " Volume Serial Number is 5824-84FE\n",
      "\n",
      " Directory of c:\\Users\\prass\\OneDrive\\Desktop\\practise\\new_env\\text-classification-using-BERT\\src\n",
      "\n",
      "02/03/2025  10:28 PM    <DIR>          .\n",
      "02/03/2025  10:50 PM    <DIR>          ..\n",
      "02/03/2025  10:50 PM    <DIR>          textClassifier\n",
      "02/03/2025  10:28 PM    <DIR>          textClassifier.egg-info\n",
      "               0 File(s)              0 bytes\n",
      "               4 Dir(s)  243,871,424,512 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\prass\\\\OneDrive\\\\desktop\\\\practise\\\\new_env\\\\text-classification-using-BERT\\\\src\\\\textClassifier\\\\utils'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.textClassifier import logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from box.exceptions import BoxValueError\n",
    "import yaml\n",
    "\n",
    "from src.textClassifier import logger # remove src in the file, else, cause bugs\n",
    "import json\n",
    "import joblib\n",
    "from ensure import ensure_annotations\n",
    "from box import ConfigBox\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "\n",
    "@ensure_annotations\n",
    "def read_yaml(path_to_yaml: Path) -> ConfigBox:\n",
    "    \"\"\"reads yaml file and returns\n",
    "\n",
    "    Args:\n",
    "        path_to_yaml (str): path like input\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if yaml file is empty\n",
    "        e: empty file\n",
    "\n",
    "    Returns:\n",
    "        ConfigBox: ConfigBox type\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(path_to_yaml) as yaml_file:\n",
    "            content = yaml.safe_load(yaml_file)\n",
    "            logger.info(f\"yaml file: {path_to_yaml} loaded successfully\")\n",
    "            return ConfigBox(content)\n",
    "    except BoxValueError:\n",
    "        raise ValueError(\"yaml file is empty\")\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    \n",
    "    \n",
    "    \n",
    "@ensure_annotations\n",
    "def create_directories(path_to_directories: list, verbose=True):\n",
    "    \"\"\"create list of directories\n",
    "\n",
    "    Args:\n",
    "        path_to_directories (list): list of path of directories\n",
    "        ignore_log (bool, optional): ignore if multiple dirs is to be created. Defaults to False.\n",
    "    \"\"\"\n",
    "    for path in path_to_directories:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        if verbose:\n",
    "            logger.info(f\"created directory at: {path}\")\n",
    "\n",
    "\n",
    "@ensure_annotations\n",
    "def save_json(path: Path, data: dict):\n",
    "    \"\"\"save json data\n",
    "\n",
    "    Args:\n",
    "        path (Path): path to json file\n",
    "        data (dict): data to be saved in json file\n",
    "    \"\"\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    logger.info(f\"json file saved at: {path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@ensure_annotations\n",
    "def load_json(path: Path) -> ConfigBox:\n",
    "    \"\"\"load json files data\n",
    "\n",
    "    Args:\n",
    "        path (Path): path to json file\n",
    "\n",
    "    Returns:\n",
    "        ConfigBox: data as class attributes instead of dict\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        content = json.load(f)\n",
    "\n",
    "    logger.info(f\"json file loaded succesfully from: {path}\")\n",
    "    return ConfigBox(content)\n",
    "\n",
    "\n",
    "@ensure_annotations\n",
    "def save_bin(data: Any, path: Path):\n",
    "    \"\"\"save binary file\n",
    "\n",
    "    Args:\n",
    "        data (Any): data to be saved as binary\n",
    "        path (Path): path to binary file\n",
    "    \"\"\"\n",
    "    joblib.dump(value=data, filename=path)\n",
    "    logger.info(f\"binary file saved at: {path}\")\n",
    "\n",
    "\n",
    "@ensure_annotations\n",
    "def load_bin(path: Path) -> Any:\n",
    "    \"\"\"load binary data\n",
    "\n",
    "    Args:\n",
    "        path (Path): path to binary file\n",
    "\n",
    "    Returns:\n",
    "        Any: object stored in the file\n",
    "    \"\"\"\n",
    "    data = joblib.load(path)\n",
    "    logger.info(f\"binary file loaded from: {path}\")\n",
    "    return data\n",
    "\n",
    "@ensure_annotations\n",
    "def get_size(path: Path) -> str:\n",
    "    \"\"\"get size in KB\n",
    "\n",
    "    Args:\n",
    "        path (Path): path of the file\n",
    "\n",
    "    Returns:\n",
    "        str: size in KB\n",
    "    \"\"\"\n",
    "    size_in_kb = round(os.path.getsize(path)/1024)\n",
    "    return f\"~ {size_in_kb} KB\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1lWML3PL0n4opSMDRhE0WvYvOSdMkFNBE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?/export=download&id=1lWML3PL0n4opSMDRhE0WvYvOSdMkFNBE\n",
      "To: c:\\Users\\prass\\OneDrive\\desktop\\practise\\new_env\\text-classification-using-BERT\\src\\textClassifier\\utils\\twwets_text_classification.zip\n",
      "100%|██████████| 843k/843k [00:00<00:00, 6.94MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'twwets_text_classification.zip'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "prefix = 'https://drive.google.com/uc?/export=download&id='\n",
    "url = 'https://drive.google.com/file/d/1lWML3PL0n4opSMDRhE0WvYvOSdMkFNBE/view?usp=drive_link'\n",
    "type(url)\n",
    "gid = url.split('/')[-2]\n",
    "print(gid)\n",
    "output = 'twwets_text_classification.zip'\n",
    "gdown.download(prefix+gid, output, quiet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1lWML3PL0n4opSMDRhE0WvYvOSdMkFNBE\n"
     ]
    }
   ],
   "source": [
    "url = 'https://drive.google.com/file/d/1lWML3PL0n4opSMDRhE0WvYvOSdMkFNBE/view?usp=drive_link'\n",
    "type(url)\n",
    "gid = url.split('/')[-2]\n",
    "print(gid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Ingestion from google Drive or from Kaggle platform"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
